environment:
  library: vmas
  scenario_name: navigation
  config_env:
    num_envs: 96
    device: cuda
    continuous_actions: false
    max_steps: 200
    n_agents: 4
    observation_shape: 10  # Example shape, adjust as needed
    action_space: 5  # Example space, adjust as needed
  logging: true
  wrappers: {}

algorithm:
  library: rllib
  name: ppo
  algo_config:
    framework: torch
    num_workers: 1
    kl_coeff: 0.01
    kl_target: 0.01
    lambda: 0.9
    clip_param: 0.2
    vf_loss_coeff: 1
    vf_clip_param: inf
    entropy_coeff: 0
    train_batch_size: 60000
    rollout_fragment_length: 125
    sgd_minibatch_size: 4096
    num_sgd_iter: 40
    num_envs_per_worker: 96
    lr: 5e-5
    gamma: 0.99
    use_gae: true
    use_critic: true
    batch_mode: truncate_episodes
    evaluation_interval: 5
    evaluation_duration: 1
    evaluation_num_workers: 0
    evaluation_parallel_to_training: false
    evaluation_config:
      num_envs_per_worker: 1
      env_config:
        num_envs: 1

simulations:
  training_episodes: 5000
  evaluation_episodes: 100
  seed: 0
